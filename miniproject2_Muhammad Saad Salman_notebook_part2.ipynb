{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-variance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will explore how bias and variance change using a dataset on college statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict,train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        College Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "0  Abilene Christian University     Yes  1660    1232     721         23   \n",
       "1            Adelphi University     Yes  2186    1924     512         16   \n",
       "2                Adrian College     Yes  1428    1097     336         22   \n",
       "\n",
       "   Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  Personal  \\\n",
       "0         52         2885          537      7440        3300    450      2200   \n",
       "1         29         2683         1227     12280        6450    750      1500   \n",
       "2         50         1036           99     11250        3750    400      1165   \n",
       "\n",
       "   PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0   70        78       18.1           12    7041         60  \n",
       "1   29        30       12.2           16   10527         56  \n",
       "2   53        66       12.9           30    8735         54  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('C:\\\\Users\\\\saads\\\\Desktop\\\\Data science\\\\my project\\\\mini project 2\\\\College.csv')\n",
    "college.rename(columns={'Unnamed: 0':'College'}, inplace=True)\n",
    "college.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the names of the variables and the data types contained in the college data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   College      777 non-null    object \n",
      " 1   Private      777 non-null    object \n",
      " 2   Apps         777 non-null    int64  \n",
      " 3   Accept       777 non-null    int64  \n",
      " 4   Enroll       777 non-null    int64  \n",
      " 5   Top10perc    777 non-null    int64  \n",
      " 6   Top25perc    777 non-null    int64  \n",
      " 7   F.Undergrad  777 non-null    int64  \n",
      " 8   P.Undergrad  777 non-null    int64  \n",
      " 9   Outstate     777 non-null    int64  \n",
      " 10  Room.Board   777 non-null    int64  \n",
      " 11  Books        777 non-null    int64  \n",
      " 12  Personal     777 non-null    int64  \n",
      " 13  PhD          777 non-null    int64  \n",
      " 14  Terminal     777 non-null    int64  \n",
      " 15  S.F.Ratio    777 non-null    float64\n",
      " 16  perc.alumni  777 non-null    int64  \n",
      " 17  Expend       777 non-null    int64  \n",
      " 18  Grad.Rate    777 non-null    int64  \n",
      "dtypes: float64(1), int64(16), object(2)\n",
      "memory usage: 115.5+ KB\n"
     ]
    }
   ],
   "source": [
    "college.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the column names (replace \".\" by \"_\" and transform to lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['college', 'private', 'apps', 'accept', 'enroll', 'top10perc',\n",
      "       'top25perc', 'f_undergrad', 'p_undergrad', 'outstate', 'room_board',\n",
      "       'books', 'personal', 'phd', 'terminal', 's_f_ratio', 'perc_alumni',\n",
      "       'expend', 'grad_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Clean the column names\n",
    "college.columns = college.columns.str.replace('.', '_').str.lower()\n",
    "\n",
    "# Display the cleaned column names\n",
    "print(college.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the variable \"Private\" into 1s and 0s rather than yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>college</th>\n",
       "      <th>private</th>\n",
       "      <th>apps</th>\n",
       "      <th>accept</th>\n",
       "      <th>enroll</th>\n",
       "      <th>top10perc</th>\n",
       "      <th>top25perc</th>\n",
       "      <th>f_undergrad</th>\n",
       "      <th>p_undergrad</th>\n",
       "      <th>outstate</th>\n",
       "      <th>room_board</th>\n",
       "      <th>books</th>\n",
       "      <th>personal</th>\n",
       "      <th>phd</th>\n",
       "      <th>terminal</th>\n",
       "      <th>s_f_ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>expend</th>\n",
       "      <th>grad_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>1</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agnes Scott College</td>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska Pacific University</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        college  private  apps  accept  enroll  top10perc  \\\n",
       "0  Abilene Christian University        1  1660    1232     721         23   \n",
       "1            Adelphi University        1  2186    1924     512         16   \n",
       "2                Adrian College        1  1428    1097     336         22   \n",
       "3           Agnes Scott College        1   417     349     137         60   \n",
       "4     Alaska Pacific University        1   193     146      55         16   \n",
       "\n",
       "   top25perc  f_undergrad  p_undergrad  outstate  room_board  books  personal  \\\n",
       "0         52         2885          537      7440        3300    450      2200   \n",
       "1         29         2683         1227     12280        6450    750      1500   \n",
       "2         50         1036           99     11250        3750    400      1165   \n",
       "3         89          510           63     12960        5450    450       875   \n",
       "4         44          249          869      7560        4120    800      1500   \n",
       "\n",
       "   phd  terminal  s_f_ratio  perc_alumni  expend  grad_rate  \n",
       "0   70        78       18.1           12    7041         60  \n",
       "1   29        30       12.2           16   10527         56  \n",
       "2   53        66       12.9           30    8735         54  \n",
       "3   92        97        7.7           37   19016         59  \n",
       "4   76        72       11.9            2   10922         15  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the 'private' column to binary values\n",
    "college['private'] = college['private'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Display the first few rows to confirm the transformation\n",
    "college.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose \"grad_rate\" as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    60\n",
      "1    56\n",
      "2    54\n",
      "3    59\n",
      "4    15\n",
      "Name: grad_rate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the target variable\n",
    "y = college['grad_rate']\n",
    "\n",
    "\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature matrix containing all variables except \"grad_rate\" and the college names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   private  apps  accept  enroll  top10perc  top25perc  f_undergrad  \\\n",
      "0        1  1660    1232     721         23         52         2885   \n",
      "1        1  2186    1924     512         16         29         2683   \n",
      "2        1  1428    1097     336         22         50         1036   \n",
      "3        1   417     349     137         60         89          510   \n",
      "4        1   193     146      55         16         44          249   \n",
      "\n",
      "   p_undergrad  outstate  room_board  books  personal  phd  terminal  \\\n",
      "0          537      7440        3300    450      2200   70        78   \n",
      "1         1227     12280        6450    750      1500   29        30   \n",
      "2           99     11250        3750    400      1165   53        66   \n",
      "3           63     12960        5450    450       875   92        97   \n",
      "4          869      7560        4120    800      1500   76        72   \n",
      "\n",
      "   s_f_ratio  perc_alumni  expend  \n",
      "0       18.1           12    7041  \n",
      "1       12.2           16   10527  \n",
      "2       12.9           30    8735  \n",
      "3        7.7           37   19016  \n",
      "4       11.9            2   10922  \n"
     ]
    }
   ],
   "source": [
    "# Define the feature variables\n",
    "X = college.drop(columns=['college', 'grad_rate'])\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the standard scaler to rescale your features and response\n",
    "\n",
    "Hint: to rescale the response variable, you will first have to bring it intro 2D-array form and later to retransform it into 1D-array form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.61255305 -0.34688182 -0.32120545 -0.0635089  -0.2585828  -0.19182742\n",
      "  -0.16811578 -0.20920713 -0.74635589 -0.96490473 -0.60231216  1.27004515\n",
      "  -0.16302792 -0.1157287   1.01377594 -0.86757419 -0.50191008]\n",
      " [ 0.61255305 -0.21088404 -0.03870299 -0.28858421 -0.6556556  -1.3539114\n",
      "  -0.20978848  0.24430705  0.45749639  1.90920787  1.21587979  0.23551492\n",
      "  -2.67564554 -3.37817594 -0.4777045  -0.5445722   0.16610985]\n",
      " [ 0.61255305 -0.40686563 -0.37631793 -0.47812132 -0.31530749 -0.2928782\n",
      "  -0.54956538 -0.49709004  0.20130469 -0.55431722 -0.90534415 -0.25958168\n",
      "  -1.20484498 -0.93134051 -0.30074919  0.58593475 -0.17728996]\n",
      " [ 0.61255305 -0.6682606  -0.68168186 -0.69242748  1.84023056  1.67761203\n",
      "  -0.65807944 -0.52075165  0.62663266  0.99679117 -0.60231216 -0.68817278\n",
      "   1.18520592  1.17565666 -1.61527433  1.15118822  1.79285145]\n",
      " [ 0.61255305 -0.72617601 -0.76455469 -0.78073454 -0.6556556  -0.59603054\n",
      "  -0.71192387  0.00900549 -0.71650831 -0.21672304  1.51891178  0.23551492\n",
      "   0.20467221 -0.52353461 -0.55354249 -1.67507915  0.24180345]]\n",
      "[-0.31825194 -0.55126184 -0.66776679 -0.37650442 -2.93961333]\n"
     ]
    }
   ],
   "source": [
    "# Reshape y into 2D array\n",
    "y = y.values.reshape(-1, 1)\n",
    "\n",
    "# Standardize the features and the target variable\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y).ravel()  # Convert back to 1D array after scaling\n",
    "\n",
    "# Display the first few rows to confirm the transformation\n",
    "print(X_scaled[:5])\n",
    "print(y_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a 10-fold cross-validated linear regression model for grad_rate using all other features. Evaluate the model performance using cross_val_score, obtain the r2_score and mean_squared_error for each fold and averaged over all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Scores for each fold: [0.57016157 0.35106799 0.38364466 0.28498425 0.2945163  0.45822425\n",
      " 0.35189315 0.54529099 0.38571707 0.50316098]\n",
      "Mean R2 Score: 0.4128661220577287\n",
      "Mean Squared Errors for each fold: [0.44930814 0.64569117 0.49227798 0.68158633 0.74024952 0.52008377\n",
      " 0.60540212 0.52538338 0.49305118 0.57612769]\n",
      "Average Mean Squared Error: 0.5729161280620108\n"
     ]
    }
   ],
   "source": [
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Obtain cross-validated predictions\n",
    "y_pred = cross_val_predict(model, X_scaled, y_scaled, cv=kf)\n",
    "\n",
    "# Compute r2_score and mean_squared_error for each fold\n",
    "r2_scores = cross_val_score(model, X_scaled, y_scaled, cv=kf, scoring='r2')\n",
    "mse_scores = -cross_val_score(model, X_scaled, y_scaled, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the average r2_score and mean_squared_error\n",
    "avg_r2_score = np.mean(r2_scores)\n",
    "avg_mse_score = np.mean(mse_scores)\n",
    "\n",
    "print(f'R2 Scores for each fold: {r2_scores}')\n",
    "print(f'Mean R2 Score: {avg_r2_score}')\n",
    "print(f'Mean Squared Errors for each fold: {mse_scores}')\n",
    "print(f'Average Mean Squared Error: {avg_mse_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function with the name `predict_from_samples` that will iteratively predict your target from different train-test splits\n",
    "\n",
    "This will be used to calculate the bias and the variance afterwards.\n",
    "We want to produce a range of different models fitted on a random choice of data points and making predictions for the remaining data points.\n",
    "\n",
    "\n",
    "Your function should:\n",
    "\n",
    "1. take the following arguments:\n",
    "    * `model`: a regression model \n",
    "    * `X`: predictor matrix/dataframe \n",
    "    * `y`: target variable \n",
    "    * `number_of_splits`: a number indicating how many times the dataset should be split randomly into training and test sets\n",
    "\n",
    "2. return a dataframe `yhat_tracker` containing columns for \n",
    "    * the true values of `y` (obtained from the `y` passed as an argument)\n",
    "    * the predictions made for y in each of the `number_of_splits` into training/test sets\n",
    "\n",
    "3. in the function body\n",
    "    - initialize the dataframe `yhat_tracker` with a single column `y` for the true values\n",
    "    - initialize a list `rowinds` containing the indices of yhat_tracker\n",
    "    - create a loop over `number_of_splits`\n",
    "        - within the loop, create a train/test split of rowinds\n",
    "        - create training and test sets from y and X by subsetting on the indices obtained from the train/test split\n",
    "        - fit the model on the training data\n",
    "        - obtain predictions for those y which are currently in the test set\n",
    "        - set the predicted values for those `y` which are currently in the training set to `np.nan` \n",
    "        - insert the predictions from the current loop as a new column into `yhat_tracker`\n",
    "    - return yhat_tracker \n",
    "    \n",
    "In the end, the returned data frame should contain one column with the true y-values and `number_of_splits` columns with predicted y-values for the different test sets. Each of the prediction columns contains only as many values as there have been in the test set each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_samples(model, X, y, number_of_splits=100):\n",
    "    \n",
    "    yhat_tracker = pd.DataFrame({'ytrue':y})\n",
    "    \n",
    "    rowinds = list(range(X.shape[0]))\n",
    "    \n",
    "    for i in range(number_of_splits):\n",
    "        \n",
    "        train_inds, test_inds = train_test_split(rowinds, test_size=0.33)\n",
    "                \n",
    "        X_train, Y_train = X.iloc[train_inds, :], y[train_inds]\n",
    "        X_test, Y_test = X.iloc[test_inds, :], y[test_inds]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        yhats = model.predict(X_test)\n",
    "        \n",
    "        yhat_tracker['sample'+str(i+1)] = np.nan\n",
    "        yhat_tracker.iloc[test_inds, -1] = yhats\n",
    "        \n",
    "    return yhat_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different predictor datasets\n",
    "\n",
    "To see what happens to bias and variance as the predictors change, create a few versions of X that have different numbers of predictors in them:\n",
    "\n",
    "* model $X$ from above including all features\n",
    "* a model $X_{small}$ including only one feature (e.g. personal)\n",
    "* a model $X_{overfit}$ created with the patsy formula below \n",
    "    - taking the cube takes into account \n",
    "        - all original features\n",
    "        - all features that could be created by squaring or cubing a single column\n",
    "        - all products of two or three different columns\n",
    "        - all products of the squared of one column with a different column\n",
    "        - -1 excludes the intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Model X_overfit: (777, 833)\n"
     ]
    }
   ],
   "source": [
    "#overfit_formula = '~ ('+' + '.join(X.columns)+')**3 -1'\n",
    "#X_overfit = patsy.dmatrix(overfit_formula, data=X, return_type='dataframe')\n",
    "# Model X_overfit (patsy formula)\n",
    "overfit_formula = '~ ('+' + '.join(X.columns)+')**3 -1'\n",
    "X_overfit = patsy.dmatrix(overfit_formula, data=college, return_type='dataframe')\n",
    "\n",
    "print(\"Shape of Model X_overfit:\", X_overfit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Model X_small: (777, 1)\n"
     ]
    }
   ],
   "source": [
    "#X_small = X[['personal']]\n",
    "# Model X_small (only one feature)\n",
    "X_small = college[['personal']]\n",
    "\n",
    "\n",
    "print(\"Shape of Model X_small:\", X_small.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `predict_from_samples` function you wrote above to get the predicted values for $X$, $X_{small}$, $X_{overfit}$ \n",
    "\n",
    "- Run each of your X through the function with the y target vector. \n",
    "- Recall that the output of your function has the true values of y in one column and then predicted values of y for the different train-test splits in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saads\\AppData\\Local\\Temp\\ipykernel_12224\\1280828711.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  yhat_tracker['sample'+str(i+1)] = np.nan\n",
      "C:\\Users\\saads\\AppData\\Local\\Temp\\ipykernel_12224\\1280828711.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  yhat_tracker['sample'+str(i+1)] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Model 𝑋:\n",
      "   ytrue    sample1    sample2    sample3    sample4  sample5    sample6  \\\n",
      "0     60  56.659838  56.374196        NaN        NaN      NaN  56.352700   \n",
      "1     56        NaN        NaN        NaN  61.083596      NaN        NaN   \n",
      "2     54        NaN        NaN        NaN  67.138497      NaN  68.257996   \n",
      "3     59  77.004029  78.746909        NaN  77.886474      NaN  75.901280   \n",
      "4     15        NaN  52.850598  53.431149  53.578379      NaN  49.946087   \n",
      "\n",
      "     sample7    sample8    sample9  ...   sample91   sample92  sample93  \\\n",
      "0        NaN  57.732334  57.042051  ...        NaN  54.125164       NaN   \n",
      "1        NaN  59.874840  64.396153  ...  64.985297  67.595098       NaN   \n",
      "2        NaN  66.885025        NaN  ...  67.685618        NaN       NaN   \n",
      "3        NaN        NaN        NaN  ...        NaN  76.713498       NaN   \n",
      "4  51.937285        NaN        NaN  ...        NaN        NaN       NaN   \n",
      "\n",
      "    sample94   sample95   sample96   sample97   sample98   sample99  sample100  \n",
      "0  58.873903  56.649269        NaN  55.637669        NaN        NaN  56.052674  \n",
      "1        NaN        NaN        NaN  66.318022  67.324163        NaN        NaN  \n",
      "2        NaN        NaN        NaN  66.942036  69.362232        NaN        NaN  \n",
      "3  77.556700        NaN        NaN        NaN        NaN        NaN  78.184574  \n",
      "4  53.979823        NaN  51.300292  52.386549  50.690888  53.328899        NaN  \n",
      "\n",
      "[5 rows x 101 columns]\n",
      "\n",
      "Predictions for Model 𝑋𝑠𝑚𝑎𝑙𝑙:\n",
      "   ytrue    sample1    sample2    sample3    sample4    sample5  sample6  \\\n",
      "0     60        NaN        NaN        NaN        NaN        NaN      NaN   \n",
      "1     56  64.668885        NaN        NaN        NaN        NaN      NaN   \n",
      "2     54  66.948811  67.244557        NaN        NaN        NaN      NaN   \n",
      "3     59        NaN  69.191045  67.713445        NaN  68.092347      NaN   \n",
      "4     15        NaN        NaN        NaN  64.850538  64.264517      NaN   \n",
      "\n",
      "     sample7    sample8    sample9  ...   sample91   sample92   sample93  \\\n",
      "0  58.598618  59.254973        NaN  ...        NaN        NaN        NaN   \n",
      "1        NaN  64.104198        NaN  ...  64.338167        NaN  63.819371   \n",
      "2        NaN        NaN  66.505588  ...  67.484109  66.976387        NaN   \n",
      "3        NaN        NaN        NaN  ...        NaN  68.683787        NaN   \n",
      "4  64.151392  64.104198  64.425276  ...        NaN        NaN        NaN   \n",
      "\n",
      "    sample94  sample95   sample96   sample97  sample98   sample99  sample100  \n",
      "0        NaN       NaN        NaN        NaN       NaN        NaN        NaN  \n",
      "1        NaN       NaN        NaN        NaN  64.91272        NaN  63.649183  \n",
      "2  65.643871       NaN        NaN  66.874428       NaN  66.985936  66.073283  \n",
      "3        NaN       NaN  69.060013        NaN       NaN        NaN        NaN  \n",
      "4  63.853458       NaN        NaN  64.477093       NaN  64.604151        NaN  \n",
      "\n",
      "[5 rows x 101 columns]\n",
      "\n",
      "Predictions for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡:\n",
      "   ytrue     sample1     sample2     sample3    sample4     sample5  sample6  \\\n",
      "0     60         NaN  -68.974183   -8.024807        NaN         NaN      NaN   \n",
      "1     56  345.471063         NaN         NaN        NaN  457.070264      NaN   \n",
      "2     54         NaN         NaN         NaN        NaN         NaN      NaN   \n",
      "3     59         NaN  235.063677         NaN  76.225826         NaN      NaN   \n",
      "4     15  154.399759 -182.554772  217.649067        NaN   12.872631      NaN   \n",
      "\n",
      "     sample7    sample8     sample9  ...    sample91   sample92    sample93  \\\n",
      "0        NaN  59.144633         NaN  ...         NaN        NaN   98.600916   \n",
      "1        NaN        NaN  256.368220  ...  126.518415        NaN         NaN   \n",
      "2        NaN  62.660920         NaN  ...         NaN  50.233810         NaN   \n",
      "3  130.69453        NaN  260.660745  ...         NaN  24.804339  216.480684   \n",
      "4        NaN        NaN         NaN  ...         NaN  79.446895  105.452569   \n",
      "\n",
      "   sample94   sample95    sample96  sample97    sample98   sample99  sample100  \n",
      "0       NaN        NaN         NaN       NaN  -18.977536 -46.947742  99.251797  \n",
      "1       NaN  90.251417 -284.852094       NaN         NaN        NaN        NaN  \n",
      "2       NaN  89.962193         NaN       NaN   84.035813  68.792972  58.984772  \n",
      "3       NaN -96.645373         NaN       NaN  139.115571        NaN  -8.185143  \n",
      "4       NaN        NaN -257.677657       NaN   66.746061        NaN  48.421050  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saads\\AppData\\Local\\Temp\\ipykernel_12224\\1280828711.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  yhat_tracker['sample'+str(i+1)] = np.nan\n"
     ]
    }
   ],
   "source": [
    "import patsy\n",
    "\n",
    "# Define the patsy formula for X_overfit\n",
    "overfit_formula = '~ ('+' + '.join(college.columns.drop(['college', 'grad_rate']))+')**3 -1'\n",
    "X_overfit = patsy.dmatrix(overfit_formula, data=college, return_type='dataframe')\n",
    "\n",
    "# Initialize a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Convert y to a 1D array\n",
    "y_1d = y.ravel()\n",
    "\n",
    "# Predictions for X\n",
    "predictions_X = predict_from_samples(model, X, y_1d)\n",
    "\n",
    "# Predictions for X_small\n",
    "predictions_X_small = predict_from_samples(model, X_small, y_1d)\n",
    "\n",
    "# Predictions for X_overfit\n",
    "predictions_X_overfit = predict_from_samples(model, X_overfit, y_1d)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Predictions for Model 𝑋:\")\n",
    "print(predictions_X.head())\n",
    "print(\"\\nPredictions for Model 𝑋𝑠𝑚𝑎𝑙𝑙:\")\n",
    "print(predictions_X_small.head())\n",
    "print(\"\\nPredictions for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡:\")\n",
    "print(predictions_X_overfit.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Calculate bias and variance \n",
    "\n",
    "Below are two functions to calculate bias and variance from the dataframe returned by your function `predict_from_samples`.\n",
    "You can use them to calculate the bias and variance for the models containing different feature combinations. \n",
    "\n",
    "If you have more predictors, variance of prediction should generally go up and bias go down. Likewise, if you have few predictors variance should go down and bias go up.\n",
    "\n",
    "For a bad model, they both might go up a lot!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bias_sq(yhats_df):\n",
    "    # Take out the true values of y that are in the first column:\n",
    "    ytrue = yhats_df.iloc[:,0]\n",
    "    \n",
    "    # Calculate the mean of the predictions, averaged across the columns.\n",
    "    # So, all of the predictions for the true y at row 0 would be averaged together\n",
    "    # and so on for all the rows.\n",
    "    yhat_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # Subtract the true value of y from the mean of the predicted values, and square it.\n",
    "    elementwise_bias_sq = (yhat_means - ytrue)**2\n",
    "    \n",
    "    # Take the mean of those squared bias values (across all y)\n",
    "    mean_bias_sq = np.mean(elementwise_bias_sq)\n",
    "\n",
    "    return mean_bias_sq\n",
    "\n",
    "def calculate_variance(yhats_df):\n",
    "    \n",
    "    # Calculate the mean of the predicted y's across the columns (mean of yhat for each row)\n",
    "    yhats_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # subtract the mean of the yhats from the original yhat values (for each row)\n",
    "    # and square the result. \n",
    "    yhats_devsq = (yhats_df.iloc[:,1:].subtract(yhats_means, axis=0))**2\n",
    "    \n",
    "    # Take the mean of the squared deviations from the mean, then \n",
    "    # take the mean of those to get the overall variance across the y observations\n",
    "    yhats_devsq_means = yhats_devsq.mean(axis=1)\n",
    "    \n",
    "    return np.mean(yhats_devsq_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias for Model 𝑋: 169.18783944639048\n",
      "Variance for Model 𝑋: 2.666793738245205\n",
      "\n",
      "Bias for Model 𝑋𝑠𝑚𝑎𝑙𝑙: 275.3175828355534\n",
      "Variance for Model 𝑋𝑠𝑚𝑎𝑙𝑙: 0.4733854655338242\n",
      "\n",
      "Bias for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡: 524158.7662522018\n",
      "Variance for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡: 4007399.4194041356\n"
     ]
    }
   ],
   "source": [
    "# Calculate bias and variance for Model 𝑋\n",
    "bias_X = calculate_bias_sq(predictions_X)\n",
    "variance_X = calculate_variance(predictions_X)\n",
    "print(\"Bias for Model 𝑋:\", bias_X)\n",
    "print(\"Variance for Model 𝑋:\", variance_X)\n",
    "\n",
    "# Calculate bias and variance for Model 𝑋𝑠𝑚𝑎𝑙𝑙\n",
    "bias_X_small = calculate_bias_sq(predictions_X_small)\n",
    "variance_X_small = calculate_variance(predictions_X_small)\n",
    "print(\"\\nBias for Model 𝑋𝑠𝑚𝑎𝑙𝑙:\", bias_X_small)\n",
    "print(\"Variance for Model 𝑋𝑠𝑚𝑎𝑙𝑙:\", variance_X_small)\n",
    "\n",
    "# Calculate bias and variance for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡\n",
    "bias_X_overfit = calculate_bias_sq(predictions_X_overfit)\n",
    "variance_X_overfit = calculate_variance(predictions_X_overfit)\n",
    "print(\"\\nBias for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡:\", bias_X_overfit)\n",
    "print(\"Variance for Model 𝑋𝑜𝑣𝑒𝑟𝑓𝑖𝑡:\", variance_X_overfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does regularization affect bias and variance?\n",
    "\n",
    "Use lasso and/or ridge regression on your dataset with all the predictor variables. In your function `predict_from_samples` replace `model` with your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso(alpha=2.0)\n",
    "ridge = Ridge(alpha=2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saads\\AppData\\Local\\Temp\\ipykernel_12224\\1280828711.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  yhat_tracker['sample'+str(i+1)] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias for Model 𝑋 with Lasso regression: 167.7460819799305\n",
      "Variance for Model 𝑋 with Lasso regression: 2.036087521983139\n",
      "\n",
      "Bias for Model 𝑋 with Ridge regression: 169.5057353414164\n",
      "Variance for Model 𝑋 with Ridge regression: 2.7400380353058433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saads\\AppData\\Local\\Temp\\ipykernel_12224\\1280828711.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  yhat_tracker['sample'+str(i+1)] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# Predictions for X using Lasso regression\n",
    "predictions_X_lasso = predict_from_samples(lasso, X, y_1d)\n",
    "\n",
    "# Predictions for X using Ridge regression\n",
    "predictions_X_ridge = predict_from_samples(ridge, X, y_1d)\n",
    "\n",
    "# Calculate bias and variance for Lasso regression\n",
    "bias_X_lasso = calculate_bias_sq(predictions_X_lasso)\n",
    "variance_X_lasso = calculate_variance(predictions_X_lasso)\n",
    "print(\"Bias for Model 𝑋 with Lasso regression:\", bias_X_lasso)\n",
    "print(\"Variance for Model 𝑋 with Lasso regression:\", variance_X_lasso)\n",
    "\n",
    "# Calculate bias and variance for Ridge regression\n",
    "bias_X_ridge = calculate_bias_sq(predictions_X_ridge)\n",
    "variance_X_ridge = calculate_variance(predictions_X_ridge)\n",
    "print(\"\\nBias for Model 𝑋 with Ridge regression:\", bias_X_ridge)\n",
    "print(\"Variance for Model 𝑋 with Ridge regression:\", variance_X_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
